\documentclass[12pt]{report}
\usepackage{graphicx}
\usepackage{tocbibind}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{float}
%\usepackage{lmodern}

\begin{document}
	
	\pagenumbering{gobble} % No page numbers 
	\begin{titlepage}
		\centering
		\vspace{0.2cm}
		\Large\textbf{KWAME NKRUMAH UNIVERSITY OF SCIENCE AND TECHNOLOGY}
		
		%\Huge\textbf{(KNUST)}
		%\vspace{0.2cm}
		\vspace{0.2cm}
		\large{DEPARTMENT OF STATISTICS AND ACTUARIAL SCIENCE}
		\vspace{0.4cm}
		
		\begin{center}
			\includegraphics[width=0.5\textwidth]{logo.png}\end{center}
		
		\large{\textbf{Decoding Student Retention and Churn of
				Vodafone (Telecel) in Kwame Nkrumah University
				of Science and Technology (KNUST) - }}
		\vspace{0.2cm}
		\large{\textbf{A Survival Analysis Approach}}
		\vspace{0.4cm}
		
		\large{Musah Faridu Oubda
			
			Kassim Asana
			
			Sarpong Linda
			
			Torsi Edmond Collins
			
			Asiamah Ezekiel}
		
		\vspace{0.8cm}  
		\small{DISSERTATION SUBMITTED TO THE DEPARTMENT OF STATISTICS AND ACTUARIAL SCIENCE, KWAME NKRUMAH UNIVERSITY OF SCIENCE AND TECHNOLOGY IN PARTIAL FULFILMENT OF THE REQUIREMENT FOR THE AWARD OF THE DEGREE OF BACHELOR OF SCIENCE IN ACTUARIAL SCIENCE}\\
		
		
	\end{titlepage}
	
	% Start numbering with Roman numerals for the Declaration
	\pagenumbering{roman}
	\chapter*{Declaration}
	
	I hereby declare that this submission is my own work towards the award of undergraduate degree and that, to the best of my knowledge, it contains no material previously published by another person nor material which had been accepted for the award of any other degree of the university, except where due acknowledgment had been made in the text.
	
	\vspace{1cm}
	
	
	\begin{tabular}{>{\bfseries}l >{\bfseries}l >{\bfseries}l}
		Name & Signature & Date \\
		\\
		Musah Faridu Oubda & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\
		Kassim Asana & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\
		Sarpong Linda & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\
		Torsi Edmond Collins & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\
		Asiamah Ezekiel & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\
	\end{tabular}
	
	\vspace{1cm}
	
	Certified by:
	
	\vspace{1cm}
	
	\begin{tabbing}
		Miss Sandra Addai-Henne \hspace{5cm} \= \dotfill \\
		\> Supervisor Signature \hspace{1cm} Date \\
		Prof. Atinuke Adebanji \hspace{5cm} \= \dotfill \\
		\> Head of Department Signature \hspace{1cm} Date \\
	\end{tabbing}
	
	
	
	
	\newpage
	\chapter*{Abstract}
	This study investigates student retention and churn of Vodafone (Telecel) services at Kwame Nkrumah University of Science and Technology (KNUST) using survival analysis approaches. The research aims to understand the factors influencing student churn, analyze patterns related to demographics and usage, and develop strategies to enhance retention rates. By focusing on KNUST students, the study seeks to improve Telecel's service offerings, enhance student experience, and strengthen the partnership between Telecel and KNUST.
	
	\newpage
	\chapter*{Dedication}
	This work is dedicated to my family and friends for their unwavering support and encouragement throughout my studies. Special thanks to my advisors and colleagues who provided invaluable insights and guidance during this research.
	
	\newpage
	\chapter*{Acknowledgement}
	% Acknowlege lectures and Mrs. Sandra
	
	\newpage
	\tableofcontents
	
	\newpage
	\listoffigures
	
	\newpage
	\listoftables
	
	
	
	
	
	\newpage
	\chapter{Introduction}
	
	% Start numbering from here
	\pagenumbering{arabic}
	
	\section{Background of Study}
	
	Ghana's telecommunications industry has experienced significant growth in recent years, with companies such as Vodafone playing a crucial role in providing mobile and internet services to people across the country \cite{bandim2022}. The industry is highly competitive, making customer retention vital for sustaining market share and profitability. Obtaining new customers is more expensive than retaining existing ones due to marketing activities, incentives, and campaigns involved. Therefore, retaining a customer is preferable to acquiring a new one. Customer churn, also known as customer attrition, refers to the loss of subscribers or customers who cease using a company’s service or product within a given period \cite{koranchirath2024}. Understanding the reasons behind customer churn helps to develop strategies to improve customer retention and help reduce churn rates in the long run.
	
	Vodafone is one of the leading national telecommunications providers in Ghana. As of January 2020, it had over 9.3 million mobile voice subscribers, representing 13.81\% of Ghana's market share. Since becoming the majority shareholder, Vodafone Ghana has been operating the Ghana Satellite Earth Station (GSES) since 2008. GSES allows Ghana to access and utilize communications satellites orbiting the Earth for various applications, such as telephone services, internet connectivity, television broadcasting, data transmission, disaster management, and emergency communications. The operation of the earth station by Vodafone Ghana proves the company's commitment to investing in and upgrading Ghana's satellite communications capabilities.
	
	In 2016, Vodafone partnered with Kwame Nkrumah University of Science and Technology (KNUST) to provide enhanced packages of services to the various faculties across the university's campuses to improve education services. This collaboration included telecommunications services such as SIM cards and data plans for the student and employee communities.
	
	In February 2023, Telecel acquired 70\% shares in Vodafone, rebranding the company name to Telecel in 2024. This rebranding aimed to improve service offerings across voice and data services, money transfers, and business solutions. Telecel, founded in 1986, is an Africa-focused telecommunication company that operates primarily in Africa and converges telecommunications with fintech, e-commerce, and tech startups.
	
	Student churn is a major issue every telecom company encounters. It leads to a loss of revenue and increases the cost of acquiring new customers. In the highly competitive telecom market, where customers have multiple service provider options, retaining customers becomes even more challenging. Companies use modern technology, computer software, and survival analysis approaches to identify at-risk students and devise strategies to enhance retention rates. This method of recognizing unsatisfied customers is known as churn prediction.
	
	On March 14, 2024, Vodafone, along with several other telecommunications companies, was hit by outages on several underwater fiber optic cables, leading to disruptions in services, particularly internet services \cite{ghanaweb2023}. It affected about 10 countries in West Africa, including Ghana. Initially, it was estimated that the problem would be fixed within 3 days; however, this was not the case. The damage was massive, affecting the West Coast route to Europe, West Africa Cable System (WACS), and the Africa Coast to Europe (ACE), resulting in MainOne and SAT3 going offline \cite{apnews2023}. The only network that was properly functioning at the moment in Ghana was AirtelTigo (AT). To quickly prevent the loss of valuable customers to AirtelTigo, Vodafone (Telecel) took the initiative to update its customers daily on their progress and offer various bonuses to prevent customers from defecting to their competitors. This continued until the problem was fixed on April 29, 2024, when the WACS cable was repaired.
	
	Previous studies have explored various factors that influence customer churn in a telecommunications company. This study aims to focus on the KNUST student population, uncover and analyze data gathered from students, apply survival analysis models to identify patterns related to churn (such as demographics, usage patterns, etc.), develop retention strategies, evaluate the success of these efforts, and make informed decisions.
	
	\section{Problem Statement}
	
	Regardless of efforts made by KNUST to partner with Telecel to provide affordable and accessible mobile communications services to the university’s populace, churn still persists. There is a lack of understanding about the factors driving student churn and retention, making it difficult to develop effective strategies to address this issue \cite{kapur2018}. This research aims to investigate the factors contributing to student churn and develop a survival analysis model for detecting at-risk students and design specific strategies to improve retention rates. It also seeks to enhance Telecel’s services, improve student experience, and foster long-term relationships between Vodafone (Telecel) and KNUST.
	
	\section{Research Objectives}
	
	\subsection{Main Objective}
	\begin{itemize}
		\item To develop a survival analysis techniques model to detect at-risk students to improve student retention and reduce churn of Telecel at KNUST.
	\end{itemize}
	
	\subsection{Specific Objectives}
	\begin{itemize}
		\item Exploring the factors that influence student churn and retention.
		\item Using survival analysis models to identify students at risk of churning.
		\item Analyzing time-to-event data to understand the patterns and timing of student churn.
		\item Identifying strategies to improve retention rates and reduce churn.
	\end{itemize}
	
	\section{Research Questions}
	\begin{itemize}
		\item What factors influence student retention and churn for Telecel services at KNUST?
		\item What is the relationship between student demographics (age, gender, year of study) and churn behavior?
		\item How does the churn rate vary with different Telecel services (voice service, data service, internet service)?
		\item How does the quality of Telecel network and services (coverage, internet speed) influence student retention and churn?
		\item How can Telecel services be optimized to better meet the needs and preferences of KNUST students?
	\end{itemize}
	
	\section{Significance of the Study}
	
	The study offers a comprehensive understanding of the factors impacting student churn from Vodafone. This will enable the development of precise strategies to enhance retention rates, thereby minimizing churn. The study will empower KNUST to improve the telecom services offered to its students. By identifying the factors influencing student retention and churn, KNUST can work closely with Telecel to guarantee the delivery of top-notch, dependable services to its students, thereby solidifying the partnership between KNUST and Telecel. The study is all about understanding what the populace expects from Vodafone (Telecel). By knowing their specific needs and preferences, the services can be improved upon. This means improved connectivity, service plans, and less hassle from switching providers. Ultimately, it ensures a more stable and reliable service for students.
	
	\section{Structure of the Study}
	
	The study on student retention and churn for Telecel services at KNUST aims to investigate the factors that drive students' decisions on Telecel services usage. The study follows a structured approach.
	
	Chapter one discusses the background information and the foundation for the research. The problem statement and goals are stated here.
	
	Chapter two of the study contains a literature review, including several studies related to the subject at hand.
	
	The third chapter focuses on the methodology and data collection techniques. There are several ways of approaching this problem, but the main focus of the study is using a survival analysis modeling tool.
	
	The fourth chapter presents the models and practical application to the dataset. Detailed analysis is presented here with the aid of figures and diagrams to determine the optimal model for the research.
	
	Chapter five delves into the conclusion and summarizes the results obtained. Based on the findings, recommendations are formulated.
	
	\section{Limitation of the Study}
	
	The limitation of this research was that the data survey only included students of KNUST who were present during the annual college elections. As a result, the coverage was limited to undergraduate students on the main campus.
	
	\newpage
	\chapter{Literature Review}
	
	
	\section{Introduction}
	Mobile technology has become widely used, changing how students interact, communicate, and obtain information \cite{Alqatani2020}. Student retention and churn are critical issues for universities and telecom companies alike. In the context of Vodafone's services offered to students, understanding student behavior and preferences is crucial for effective retention strategies. This project addresses this gap using survival analysis, a statistical method for examining data over time \cite{BoxSteffensmeier2020}. In this context, the event of interest is student churn, defined as the discontinuation or cessation of Vodafone SIM cards. By applying survival analysis, this project will provide valuable insights into student retention and churn factors.
	
	\subsection{Telecommunication Industry and Customer Behavior}
	The telecommunication industry is highly competitive, with customer acquisition and retention being pivotal to a company's success. Research indicates that factors such as service, pricing, customer support, and competitive offerings significantly influence customer churn \cite{Lai2021}.
	
	\subsection{Student Retention and Telecom Services}
	Students, as a demographic, exhibit unique usage patterns and service expectations. Studies show that reliable connectivity, affordable pricing, and additional benefits like educational resources influence their choice of telecom services \cite{SmithBrown2020}. For telecom companies, understanding these factors is crucial to tailoring services that meet students’ needs and enhance retention.
	
	\subsection{History of Survival Analysis (SA)}
	The origins of SA and its history spread far back to the early work on mortality by John Graunt, who published the book \textit{Natural and Political Observations on the Bills of Mortality} in 1662. The concept of “Life Tables” was introduced in this book. A new, modern era in SA started during World War II in the USA, where the reliability of military equipment was tested using SA. After World War II, SA became popular and spread to various other disciplines \cite{Jerenz2008}. The most influential papers on SA were published by Kaplan and Meier \cite{Kaplan1958} and Cox \cite{Cox1972}, in which the Kaplan-Meier product limit estimator and Cox proportional hazard model were introduced, respectively.
	
	\subsection{Application of Survival Analysis}
	Survival analysis (SA) has been successfully applied in diverse fields, including medical research, engineering (reliability analysis), finance, and economics. In finance, SA has been used to analyze a firm's vulnerability to global financial crises and identify firms at risk of failure, enabling timely interventions \cite{Lee2014, Pereira2014, Kumar2015, Iwasaki2014}. SA has also been employed to predict the optimal time to buy or sell stocks within the stock market \cite{Kumar2015}. In the banking sector, SA is utilized to assess banks' survival during financial crises, measure their strength when entering new markets \cite{Leung2010, Evrensel2008}, and conduct credit risk analysis \cite{Tsujitani2012, Baesens2005}. The widespread adoption of SA across these domains underscores its versatility and effectiveness in modeling time-to-event data and identifying the factors that influence outcomes of interest.
	
	\section{Conceptual Review}
	
	\subsubsection{Customer Retention and Churn}
	Customer retention refers to a company's capacity or ability to maintain or retain their customer base over a specific period. High retention rates are crucial for maintaining revenue streams, reducing marketing costs associated with acquiring new customers, and fostering a positive brand reputation. Customer churn, also known as customer attrition, is the rate at which customers stop using a company's product or service. It can be caused by various factors such as dissatisfaction with the service, better offers from competitors, or changes in personal circumstances. In the telecommunications industry, market competitiveness is measured by churn rate. Telephone, internet, and mobile services are all part of telecommunications.
	
	\section{Empirical Studies}
	
	Imani, M. (2020) \textit{Customer Churn Prediction in Telecommunication Using Machine Learning: A Comparison Study}. The paper tackles customer churn in telecoms, emphasizing that retaining customers is cheaper than acquiring new ones. It evaluates various machine learning methods for predicting churn by comparing classifiers, target detectors, feature extraction, and feature selection techniques. The study finds that Random Forest and Feed-Forward Neural Networks with Genetic Algorithm showed high accuracy. Effective target detectors included Spectral Angle Mapper and Adaptive Subspace Detector. Clustering-Based Feature Extraction and Advanced Binary Ant Colony Optimization excelled in improving classification and feature selection. The study recommends implementing Random Forest and Neural Networks for effective churn prediction.
	
	Melik Masarifoglu and Ali Hakan Buyuklu \textit{Applying Survival Analysis to Telecom Churn Data}. This paper emphasizes the importance of customer retention in telecoms, noting that retaining customers is more cost-effective than acquiring new ones. It employs survival analysis to estimate customer survival and hazard functions, focusing on factors like campaigns, tariffs, tenure, age, and auto-payment. The paper introduces survival analysis (SA) as a statistical method to analyze time-to-event data. It describes the Cox Proportional Hazard Model (CPHM), a widely used technique for quantifying the risk of an event occurring during the observation period. The paper uses Kaplan-Meier estimates and the Cox model to analyze the impact of various predictors on customer churn. The results show how different factors, such as campaigns and tariffs, affect customer survival probabilities. The study finds that survival analysis is effective for predicting churn and recommends its use for targeting at-risk customers and improving retention strategies.
	
	Kavitha, V., Kumar, G. H., Kumar, S. M., \& Harish, M. (2020) \textit{Churn prediction of customer in telecom industry using machine learning algorithms}. This paper highlights the importance of customer churn in the telecommunications industry, noting its impact on revenue and customer lifetime value. It stresses the need for predictive models to identify potential churners and improve retention by enhancing service offerings. The methodology involves collecting data from Kaggle, preprocessing it by filtering and standardizing, and selecting relevant features. The prediction and classification phase uses Random Forest, Logistic Regression, and XGBoost algorithms, with each trained and tested to evaluate performance. The results reveal that Random Forest outperforms Logistic Regression and XGBoost in accuracy and performance. Visualizations, including confusion matrices and accuracy graphs, support these findings. The paper concludes by emphasizing that churn prediction is crucial for telecoms and suggests exploring lazy learning and AI techniques for future research.
	
	
	
	\newpage
	\chapter{Methodology}
	
	\section{Introduction}
	
	The chapter structures the methods and procedures followed for the analysis to predict student churn of Vodafone (Telecel) in KNUST. A comprehensive explanation of the models, mathematical formulations and interpretations are presented here. The paper compares model performance using the Concordance Index thus shedding light on their predictive capabilities and practical applications on the topic.
	
	\section{Research Design}
	
	The study employs quantitative research. This type of research aims to establish the cause-and-effect relationships between variables. Specifically, it focuses on quantifying various aspects of students’ usage and satisfaction, rather than exploring underlying meanings or personal experiences in an open-ended manner.
	
	\section{Pilot Survey}
	
	Before the actual statistics were carried out, a pilot survey was held to grasp the scope of students’ understanding to the topic. It was carried out using the residence of Otumfuo Osei Tutu II (popularly known as SRC hostel) on campus. Out of 150 questionnaires sent out, a total of 137 respondents were returned. Most of the respondents were males and this could have been as a result of having females conduct the survey. This was done to improve the reliability of the data.
	
	\section{Data Collection}
	
	The primary data source for this research was a survey conducted among students at Kwame Nkrumah University of Science and Technology (KNUST). The survey targeted students across different academic levels (from level 100 to 600) during the annual college elections. The dataset includes a variety of questions, each capturing specific aspects relevant to our study with the aid of Google Forms.
	
	The data collection process involved obtaining relevant information while ensuring confidentiality and ethical considerations.
	
	\section{Sample Size}
	
	The sample size of the research was determined through cluster sampling. Cluster sampling is a sampling technique in which the population is divided into groups known as clusters. A random sample is then selected from each cluster ensuring that, each cluster has an equal number of elements. It is therefore homogeneous within but heterogeneous around (clusters 
	
	are different from one another but the elements within it share common factors). This sampling is employed to determine the optimal sample size as it is a robust method that allows to efficiently estimate the population by selecting entire clusters (colleges within KNUST) rather than using individual students.
	
	The sample size for cluster sampling can be determined using the formula below:
	
	\[n_0=\frac{z^2\ast p\ast\left(1-p\right)}{E^2}\]
	\[n=\frac{n_0}{1+(\frac{n_0-1}{N})}\]
	\[n_{cluster}=n\ \ast\ DEFF\]
	
	Where:
	\begin{itemize}
		\item \((N)\ \)is the population size.
		\item \((n_0)\) is the sample size for simple random sampling
		\item \((n)\)\ is the sample size for the population.
		\item \((n_{cluster})\) is the sample size of the clusters.
		\item \((z) \)represents the critical value.
		\item \((p)\) is the estimated proportion of the population (e.g., proportion of students with a certain behavior).
		\item \((DEFF) \) is the design effect, which accounts for the correlation among observations within the same cluster.
		\item \((E) \) is the margin of error.
	\end{itemize}
	
	Parameter Justification:
	
	\begin{itemize}
		\item \textbf{Z-score} \((z)\): A confidence level of 95\% is chosen therefore resulting to a Z-score of 1.96.
		\item \textbf{Population}\( (N)\): The population size of KNUST students is about 85000.
		\item \textbf{Estimated Proportion \((p)\)}: To maximize sample size, we use 0.5.
		\item \textbf{Margin of Error }\((E)\): 5\% since the confidence Level is 95\%.
		
		
	\end{itemize}
	
	
	\[n_0\ =\frac{\left({1.96}^2\ast\ 0.5\ \ast\ 0.5\ \right)}{{0.05}^2}\]
	\[n_0\approx383.82\]
	\[n_0\approx384\]
	\[n=\frac{384}{1+(\frac{384-1}{85000})}\]
	\[n\approx384.16\]
	\[n\approx384\]
	
	\begin{itemize}
		\item \textbf{Design Effect} (\({DEFF})\): The design effect of 2 is used as the benchmark.
		
	\end{itemize}
	\[n_{cluster}=384\ \ast\ 2\]
	\[n_{cluster}=768\]
	
	A cluster sample size of 768 students from the population of about 85000.
	
	Since there are 6 clusters from which each represents the colleges, the sample size is evenly allocated across the clusters. Each cluster would have approximately 128 students.
	
	
	
	\section{Data Pre-Processing}
	
	In the realm of data analysis, ensuring the quality and suitability of data is paramount for deriving meaningful insights and making informed decisions. The initial phase of the study involved a thorough examination of the dataset to identify and handle missing data appropriately to ensure that subsequent analyses are conducted on a complete and representative dataset. One of the critical preprocessing tasks involved the transformation of categorical variables into numeric format. This was achieved using label encoding, a technique that assigns unique integer labels to each category with the aid of python. The transformation structured the dataset to facilitate survival analysis. The data was then organized to facilitate essential components such as time duration, event indicators, and relevant covariates to the variables. 
	
	\section{Concept of Survival Analysis}
	
	Survival analysis is a branch of statistics used to analyze time-to-event data. The primary interest lies in the time until the occurrence of the event of interest. This could be anything from the failure of a mechanical part to the occurrence of a disease all the way to the death of a patient. The time variable is usually referred to as survival time since it gives the time that an individual has survived over some follow-up period. The event is also referred to as a failure because the event of interest is usually death, disease incidence, or some other negative experience. There are some special cases where the failure is a positive event and not a negative one.
	
	\section{Censoring}
	
	In survival analysis, not all subjects may experience the event of interest within the study period. Censoring occurs when the survival time of a subject is not fully observed. It occurs when a subject leaves the study before an event occurs, or when the study ends before the event has occurred for all subjects.
	
	
	\subsection{Right-Censored}
	
	It occurs when a subject has some loss to follow up or the study ends before the event of interest occurs. The lifetime is known to exceed a certain value meaning that, true survival time is equal to or greater than the observed survival time.
	
	\subsection{Left-Censored}
	
	It occurs when the event of interest has occurred before the study starts, and thus the exact survival time is known only to be less than a certain value indicating that the true survival time is less than or equal to the observed survival time.
	
	\subsection{Interval-Censored}
	
	It can occur if a subject’s true but unobserved survival time is within a certain known specified time interval. 
	\begin{figure}
		\centering
		\includegraphics[width=0.5\linewidth]{Figure 3/3.1.png}
		\caption{Interval Censoring}
		\label{Figure 3.1}
	\end{figure}
	
	Interval-censoring incorporates both right-censoring and left-censoring. Left-censored data occurs whenever the value is 0 and  is a known upper bound on the true survival time. In contrast to the left-censored, right-censored data occurs whenever the value of  is infinity, and is a known lower bound on the true survival time.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=01\linewidth]{Figure 3/3.2.png}
		\caption{Censoring Graph}
		\label{Figure 3.2}
	\end{figure}
	
	
	\begin{itemize}
		
		\item \(C\) indicates censored data
		\item  \(X\) indicates observed events
		
		
	\end{itemize}
	
	Figure 3.2 illustrates the different types of censoring in a survival analysis study conducted over 6 weeks. Case 1 and Case 6 are right-censoring. The participant was followed from the start of the study until about 4 weeks, at which point they were censored (indicated by ). This could mean the participant dropped out of the study or the study ended before an event occurred for this individual. Cases 2 and 4 are another instance of right censoring, but their participants joined the study later and still did not experience the event of interest. Case 3 and Case 5 show an observed event (indicated by ) occurring at around 4 weeks and 6 weeks respectively. This is not censored data, as the event of interest was observed within the study period.
	
	\section{Fundamental Concepts of Survival Analysis}
	
	These functions are complementary in understanding the dynamics of survival data, namely survival function and hazard function. They are the building blocks for every survival analysis. They clearly have a defined relationship between the two. The \(S\left(t\right)\) can be derived from the \(h\left(t\right)\) complement one another such that, one can be derived from the other.
	
	\[S\left(t\right)=\ exp\left[-\int_{0}^{t}{h(x)dx}\right]\]
	
	\[h\left(t\right)=\ -\left[\frac{dS\left(t\right)/dt\ }{S(t)}\right]\]
	
	
	
	The first formula describes how the survival function \(S\left(t\right)\) can be written in terms of an integral involving the hazard function. The formula states that \(S\left(t\right) \)equals the exponential of the negative integral of the hazard function \(h\left(t\right) \) between integration limits of 0 and t. 
	The second formula describes how the hazard function \(h\left(t\right) \) can be written in terms of a derivative involving the survival function. The formula states that \( h\left(t\right)\) equals minus the derivative of \(S\left(t\right) \) with respect to t divided by \(S\left(t\right)\).
	
	
	\subsection{\texorpdfstring{Survival Function \( S(t) \)}{Survival Function S(t)}}
	The survival function \(S\left(t\right) \) is also known as the survival probability function gives the probability a person survives longer than some specified time \( t\).
	
	\[S(t)\ =\ P(T\ >\ t)\]
	The survival function is very fundamental to a survival analysis as it helps in determining survival probabilities for different values of time  to provide crucial summary information from the data.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.47\textwidth]{Figure 3/3.31.png}
		\hfill
		\includegraphics[width=0.47\textwidth]{Figure 3/3.32.png}
		\caption{Survivor Curves}
		\label{Figure 3.3}
	\end{figure}
	
	The figure on the left in Figure 3.3 is a theoretical curve of the survival function\ \(S\left(t\right) \) which ranges from 0 up to infinity. It is non-increasing and therefore slopes downward as t increases. At time 0, \(S\left(t\right)=1\) and when \( t\ =\ \infty , S\left(\infty\right)\ =\ 0.\) At, the start of the study, no event occurs and it is assumed that if the study period is without a limit, the survivor curve will eventually reach 0.
	When actual data is used, the survivor curve does not result to a smooth curve but rather a step function. The step function is illustrated on the right in Figure 3.3. Since the study period is never infinite in duration as there may be competing risks for failure, it is possible that not everyone obtains the event of interest. The estimated survivor function \(\hat{S}\left(t\right)\), thus may not go all the way down to 0 at the end of the study.
	
	\subsection{\texorpdfstring{Hazard Function \( h(t) \)}{Hazard Function h(t)}}
	
	The hazard function \( h(t)\ \)denotes the instantaneous rate of failure at time\ (t), given that the subject has survived up to time\( (t).\)
	
	\[
	h(t) = \lim_{\Delta t \to 0} \frac{P(t \le T < t + \Delta t \mid T \geq t)}{\Delta t}
	\]
	
	\[h\left(t\right)\geq0\]
	
	
	The hazard function \( h\left(t\right)\), is given by the formula: \(h\left(t\right)\ \)equals the limit, as \(\Delta t \) approaches zero, of a probability statement about survival, divided by \(\Delta t\), where \(\Delta t\) denotes a small interval of time.
	
	The hazard function is also known as the conditional failure rate. It is a rate rather than a probability. In the hazard function formula, the expression to the right of the limit sign gives the ratio of two quantities. The numerator is a conditional probability while the denominator, \(\Delta t\) denotes a small-time interval. By the division, a probability per unit of time is obtained, which is no longer a probability but a rate. In particular, the scale for this ratio is not 0 to 1 like a probability but rather ranges between 0 and infinity while depending on whether time is measured in days, weeks, months, or years. 
	
	\[H(t)=\int_{0}^{t}{h(x)dx}\]
	
	The cumulative hazard function \(H(t)\) can be derived from the hazard function. It is the integral of the hazard function up to time \(t\). It represents the total hazard experienced up to time \( t. H(t)\) provides a straightforward cumulative measure of risk or failure over time.
	
	\section{Approaches in Survival Analysis}
	
	There are various approaches to determine the type of survival model to use. Each approach has its strengths and weaknesses, and the choice typically involves balancing statistical assumptions, data characteristics, and the complexity of the survival patterns to model.
	
	\subsection{Parametric Methods}
	
	These methods assume that the survival times follow a specific statistical distribution. Common parametric survival models are exponential, Weibull, log-normal and gamma models. They estimate parameters using maximum likelihood estimation or Bayesian methods.
	
	\subsection{Non-Parametric Methods}
	
	These methods include approaches that make minimal assumptions about the form of the survival distribution. Common non-parametric methods in survival analysis are the Kaplan-Meier Estimator, Nelson-Aalen Estimator and Log-Rank Test.
	
	\subsection{Semi-Parametric Methods}
	
	Semi-parametric models combine parametric elements (the effect of covariates) with non-parametric elements (the baseline hazard function). It is primarily represented by the Cox Proportional Hazard Model.
	
	\section{Kaplan Meier}
	The Kaplan-Meier estimator is employed in survival analysis to analyze the time until an event occurs. The Kaplan-Meier estimator calculates the survival probability at a specific time step by multiplying the probability of surviving each previous time step.
	Let \( S(t) \) be the survival probability at time. The estimator is computed as
	
	\[S\left(t\right)=\prod_{i:t_i\le t}\left(1-\frac{d_i}{n_i}\right)\]
	
	Where:
	\begin{itemize}
		\item \(t\) is a time
		\item \(d_i \) the number of events (churn) at time \(t_i\)
		\item \(S\left(t\right)\ \)is the survival probability at time \(t\)
		\item \(n_i\) is the number of individuals at risk just before time \(t_i\)
	\end{itemize}
	The estimator essentially calculates the probability of surviving from one time step to the next, and the product of these probabilities gives the overall survival probability up to time \(t\).
	
	\section{Cox Proportional (Cox PH) Hazard Model}
	
	The Cox Proportional Hazards model is a popular semi-parametric model for survival analysis by Sir David Cox (1924). It models the relationship between the survival time and a set of predictors.
	
	\[
	h\left(t \mid x\right) = h_0(t) \exp(\beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p)
	\]
	
	Where:
	\begin{itemize}
		\item \(h(t\mid x)\) is the hazard function, i.e., the instantaneous rate of the event occurring at time \(t\) given the predictor variables \(x\).
		\item \(h_0\left(t\right)\) is the baseline hazard function, representing the hazard for individuals with all predictor variables equal to zero.
		\item \(\beta_1,\beta_2,\ldots,\beta_p\) are the coefficients for the predictor variables
	\end{itemize}
	
	The coefficients \(\beta\) are estimated using maximum likelihood estimation, and the model assumes a proportional hazard ratio, meaning the effect of the predictors on the hazard is constant over time.
	An important assumption on the Cox PH is that it has a constant hazard function proportion for each time.
	
	
	
	\(H_0\): The Assumption of Proportional Hazard is fulfilled 
	
	\(H_1\): The Assumption of Proportional Hazard is not fulfilled 
	
	
	\section{Accelerated Failure Time (AFT)}
	
	In situations where the Cox proportional is not satisfied, the parametric model approach can be used. Accelerated Failure Time (AFT) is one of the popular parametric models used in survival analysis. The model assumes that the survival function \(S(t)\) follows a parametric continuous distribution. This implies that, the distribution is following a Weibull, lognormal or exponential distribution. The aim of an AFT is to account for the influence of multiple covariates on the survival time by either accelerating or decelerating it.
	
	\[\lambda(x)\ =\ exp(b_0\ +\ \sum_{i=1}^{n}{b_ix_i)}\]
	
	Where:
	\begin{itemize}
		\item \(\lambda(x)\) is the accelerating factor
		\item \(b_0 \) is the baseline accelerating factor when all covariates are 0
		\item \(b_i\) is the regression coefficient
		\item \(x_i\) are the covariates
		
	\end{itemize}
	
	\section{Akaike Information Criterion (AIC)}
	
	The Akaike Information Criterion (AIC) is a measure of the relative quality of statistical models for a given dataset. It aids in model selection in survival analysis. It contributes by penalizing models with more parameters to avoid the problem of overfitting. The lower the AIC value, the better the model is considered to fit the data.
	
	\[AIC=2k-2ln(L),\]
	
	Where:
	\begin{itemize}
		\item \(k \) is the number of parameters in the model.
		\item \(L\) is the likelihood of the model
	\end{itemize}
	
	\section{Concordance Index in Survival Analysis}
	
	The Concordance Index, often referred to as the C-index or Harrell's C-index, is a statistical metric used to evaluate the performance of models in survival analysis. It assesses how well a model discriminates between subjects in terms of their event times and predicted risks. 
	
	The Concordance Index measures the model's ability to correctly rank the predicted risks of individuals based on their actual event times. The Concordance Index evaluates whether the model's predicted risks align with the observed event times.
	
	\[C=\frac{Number\ of\ Concordant\ Pairs}{Number\ of\ Concordant\ Pairs\ +Number\ of\ Discordant\ Pairs}\]
	
	A \(C\) value above 0.5 suggests that the model has predictive ability better than random chance. A higher \(C\) value implies a better model performance and more accurate risk predictions.
	
	
	
	\newpage
	\chapter{Analysis and Findings}
	\section{Introduction}
	
	This section presents the study's findings and discusses what each output means towards the research goals. It includes easy-to-read tables, graphs, and computer results based on the methods used. The analysis closely examines details towards the model building, diagnostics and evaluation. The information here was obtained from using python for computer analysis during the research. This chapter seeks to explain the use of survival models in the methodology to determine the Vodafone (Telecel) churn rate among students.
	
	\section{Data Description}
	
	The dataset has a shape consisting of 768 rows and 18 columns from a sample in KNUST.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{|>{\raggedright\arraybackslash}p{4cm}|p{9cm}|} \hline  
			
			\textbf{Field Name} & \textbf{Description} \\ \hline  
			
			Gender & Gender of the student \\ \hline  
			College & College the student belongs to \\ \hline  
			Churn & Whether the student has churned or not \\ \hline  
			Level & Academic level of the student \\ \hline  
			Residence & Whether the student lives on-campus or off-campus \\ \hline  
			Usage Freq& Frequency of Vodafone network usage \\ \hline  
			Network Strength& Strength of the Vodafone network \\ \hline  
			Voice Calls& Usage of voice calls \\ \hline  
			Mobile Data Internet& Usage of mobile data for internet \\ \hline  
			SMS Text Messaging& Usage of SMS text messaging \\ \hline  
			Data Exhaustion& Whether the student uses the entire 5GB in a month \\ \hline  
			Multiple Networks& Whether the student uses multiple networks \\ \hline  
			Other Networks Better Services& Whether other networks provide better services \\ \hline  
			Poor Network Coverage& Whether the student experiences poor network coverage \\ \hline  
			Insufficient Data Allowance& Whether the student finds data allowance insufficient \\ \hline  
			Unsatisfactory Customer Service& Whether the student is dissatisfied with customer service \\ \hline  
			High Costs Pricing& Whether the student finds Vodafone's pricing high \\ \hline  
			Monthly Data Usage& Monthly data usage of a student in gigabytes \\ \hline 
			
		\end{tabular}
		\caption{Field Names and Descriptions}
	\end{table}
	
	
	\section{Model Building}
	
	The lifelines package played a pivotal role in this section by providing essential survival analysis models in Python. These models are crucial for analyzing data where the time student churn event is important. 
	
	
	\subsection{Kaplan Meier (KM) Curve}
	
	A Kaplan-Meier curve, also known as a survival curve, is a statistical tool used in survival analysis to estimate the survival function from timeline data. It provides a way to visualize the proportion of individuals surviving over time, taking into account censored data (individuals who have not experienced the event by the end of the observation period).
	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{Figure 4/4.1.png}
		\caption{Kaplan Meier Curve of students from levels 100–500}
	\end{figure}
	
	The Kaplan-Meier survival curve provided is a tool to estimate the probability that students will remain enrolled over a given time period. The x-axis represents the timeline, which in this ranges from 1 to 5 levels or years. The 0 indicates when the study began. The y-axis represents survival probability and ranges from 0 to 1.
	
	
	The KM estimate line graph shows the survival probability at various points along the study. Each step down indicates an event, which decreases the overall survival probability. The shaded area around the line suggests the confidence interval, giving a range within which the true survival curve is expected to lie.
	
	In churn prediction, this curve helps identify critical time points where student retention drops significantly and allows institutions to intervene proactively. For instance, if there’s a notable step down at a particular time point on the x-axis (3–4), it might indicate a period when students are more likely to leave and thus could be a target for retention efforts.
	
	
	
	\subsection{Kaplan Meier Analysis}
	
	The provided Kaplan-Meier estimator output in Table 4.2 below summarizes the survival curve in table 4.1 over level in KNUST.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|} \hline 
			
			\textbf{Event Time} & \textbf{Number at Risk} & \textbf{Number of Censored} & \textbf{Survival Probability} & \textbf{Lower Confidence Interval} & \textbf{Upper Confidence Interval} \\ \hline 
			
			0 & 768 & 0 & 1.000000 & 1.000000 & 1.000000 \\ \hline  
			1 & 768 & 35 & 0.954427 & 0.937099 & 0.967065 \\ \hline  
			2 & 733 & 37 & 0.890799 & 0.864030 & 0.912565 \\ \hline  
			3 & 696 & 33 & 0.802521 & 0.763671 & 0.835681 \\ \hline  
			4 & 663 & 17 & 0.667443 & 0.597011 & 0.728409 \\ \hline  
			5 & 646 & 2 & 0.500583 & 0.285044 & 0.682828 \\ \hline 
		\end{tabular}
		\caption{Kaplan-Meier Estimate Analysis}
	\end{table}
	
	
	Initially, at time 0 (when students initially start the academic year), all 768 students are considered to be at risk. With no events (churns) recorded yet, the survival probability is 1.
	As the students ascend the academic ladder, the number at risk begins to gradually decrease as some begin to experience the event. The higher the number of events, the more the number at risk decreases. This can be seen for example, in the 2\(^{nd}\)  level where the initial 768 students from the beginning of the 1\(^{st}\) year decreased to 733 for the 2\(^{nd}\) year after 35 students churned at the end of the year. Subsequently, the survival probability declines gradually from 1 to 0.500583 by the 5\(^{th}\) year. The confidence intervals (Lower Cl and Upper CI) provide ranges within which the true survival probabilities lie with a certain level of confidence.
	
	
	\subsection{Cox Proportional Hazard (COX PH)}
	
	The analysis was continued by doing the Cox Proportional Hazard modeling. In the Cox Proportional Hazard modeling, there are two things that are done, namely partial testing for each predictor variable and testing the Cox Proportional Hazard assumption. 
	
	The Cox Proportional hazards regression model can be expressed as follows:
	
	
	\begin{align*}
		h(t,x) = h_0(t) \exp(&-0.56 \cdot \text{Gender} - 0.03 \cdot \text{College} - 0.09 \cdot \text{Residence} \\
		&- 0 \cdot \text{Usage\_Freq} + 0.23 \cdot \text{Network\_Strength} \\
		&+ 0.16 \cdot \text{Voice\_Calls} \\
		&+ 0.32 \cdot \text{Mobile\_Data\_Internet} - 0.1 \cdot \text{SMS\_Text\_Messaging} \\
		&+ 0.41 \cdot \text{Data\_Exhaustion} - 0.21 \cdot \text{Multiple\_Networks} \\
		&+ 0.13 \cdot \text{Other\_Networks\_Better\_Services} \\
		&- 0.17 \cdot \text{Poor\_Network\_Quality\_Coverage} \\
		&- 0.12 \cdot \text{Insufficient\_Data\_Allowance} \\
		&- 0.15 \cdot \text{Unsatisfactory\_Customer\_Service} \\
		&+ 0.16 \cdot \text{High\_Costs\_Pricing} - 0.06 \cdot \text{Monthly\_Data\_Usage})
	\end{align*}
	
	
	Furthermore, the results of parameter estimation and partial testing are presented in the Table below.
	
	% Insert another Table
	
	\begin{table}[H]
		\centering
		\begin{tabular}{|p{4cm}|p{2cm}|p{2.5cm}|p{2.5cm}|p{1.5cm}|} \hline 
			
			\textbf{Variable} & \textbf{Coefficient} & \textbf{EXP (Coefficient)}& \textbf{SE (Coefficient)}& \textbf{P} \\ \hline
			Gender & -0.56 & 0.57 & 0.20 & \(<\)0.005 \\ \hline  
			College & -0.03 & 0.97 & 0.05 & 0.51 \\ \hline  
			Residence & -0.09 & 0.91 & 0.20 & 0.65 \\ \hline  
			Usage Freq& -0.00 & 1.00 & 0.06 & 0.96 \\ \hline  
			Network Strength& 0.23 & 1.26 & 0.08 & \(<\)0.005 \\ \hline  
			Voice Calls& 0.16 & 1.18 & 0.23 & 0.48 \\ \hline  
			Mobile Data Internet& 0.32 & 1.37 & 0.27 & 0.24 \\ \hline  
			SMS Messaging& -0.10 & 0.90 & 0.18 & 0.58 \\ \hline  
			Data Exhaustion& 0.41 & 1.51 & 0.28 & 0.14 \\ \hline  
			Multiple Networks& 0.21 & 1.23 & 0.42 & 0.62 \\ \hline  
			Other Networks Better Services& 0.13 & 1.14 & 0.25 & 0.59 \\ \hline  
			Poor Network Quality Coverage& -0.17 & 0.85 & 0.19 & 0.38 \\ \hline  
			Insufficient Data Allowance& 0.12 & 1.12 & 0.19 & 0.54 \\ \hline  
			Unsatisfactory Customer Service& -0.15 & 0.86 & 0.18 & 0.40 \\ \hline  
			High Costs Pricing& 0.16 & 1.18 & 0.18 & 0.36 \\ \hline  
			Monthly Data Usage& -0.06 & 0.94 & 0.07 & 0.38 \\ \hline 
		\end{tabular}
		\caption{Detailed Cox PH Analysis}
	\end{table}
	
	The coefficient and exp(coefficient) columns provide information about the relationship between each independent variable and the dependent variable. A positive coefficient or exp(coefficient) \(> \)1 (such as Network Strength and Voice Calls) indicates that an increase in the independent variable is associated with an increase in the odds of the outcome. These increase the hazard (risk) of churn. A higher value of these variables is associated with a higher likelihood of churn. 
	
	Conversely, a negative coefficient or exp(coefficient)  \(<\) 1 (such as Poor Network Quality Coverage and Unsatisfactory Customer Service) suggests a decrease in the odds of the outcome. These decrease the hazard (risk) of churn. A higher value of these variables is associated with a lower likelihood of churn.
	The p-value column helps assess the statistical significance of each independent variable. A low p-value (typically  \(<\) 0.05) indicates that the variable is likely to have a meaningful impact on the outcome. This can be seen in Network Strength and Gender.
	
	\begin{figure}{H}
		\centering
		\includegraphics[width=1\linewidth]{Figure 4/4.2.png}
		\caption{Coefficients of Cox PH}
	\end{figure}
	
	A coefficient to the right of zero (positive log hazard ratio) indicates that an increase in that variable is associated with a higher risk of student churn. A coefficient to the left of zero (negative log hazard ratio) indicates that an increase in that covariate is associated with a lower risk of student churn.
	The further a coefficient is from zero, the stronger the effect of that covariate on the hazard of churn.
	
	\subsection{\textbf{Cox PH assumption Test}
	}
	This test checks if the impact of the predictor variables on the hazard rate is constant over time. Covariates violating this assumption might need further investigation or transformation.	
	
	The null hypothesis states that there is a significant relationship between the predictor variables (such as College and Voice Calls) and the likelihood of a student churning.
	
	The alternative hypothesis suggests that there is no significant association between the predictor variables and the likelihood of churn.
	
	%insert table
	
	\begin{table}[H]
		\centering
		\begin{tabular}{lcc}
			\toprule
			\textbf{Covariates} & \textbf{Test statistic} & \textbf{p} \\
			\midrule
			College & 0.26 & 0.61 \\
			Data Exhaustion & 0.28 & 0.60 \\
			Gender & 0.25 & 0.62 \\
			High Costs Pricing & 3.61 & 0.06 \\
			Insufficient Data Allowance & 1.45 & 0.23 \\
			Mobile Data Internet & 0.21 & 0.64 \\
			Monthly Data Usage & 0.10 & 0.75 \\
			Multiple Networks & 1.48 & 0.22 \\
			Network Strength & 1.43 & 0.23 \\
			Other Networks Better Services & 0.39 & 0.53 \\
			Poor Network Quality Coverage & 0.60 & 0.44 \\
			Residence & 0.09 & 0.77 \\
			SMS Text Messaging & 1.13 & 0.29 \\
			Unsatisfactory Customer Service & 0.26 & 0.61 \\
			Usage Freq & 0.03 & 0.86 \\
			Voice Calls & 1.60 & 0.21 \\
			\bottomrule
		\end{tabular}
		\caption{Cox PH assumption test}
	\end{table}
	
	The Cox Proportional Hazard method has a weakness which is that the proportional hazard assumption must be met. In Table 4.3, it can be seen that the covariate meets the assumptions as none of the covariates have p-values below 0.05, which suggests that there is strong evidence for the proportional hazard’s assumption for any single covariate.
	
	This means that, based on this test, the assumption that the hazard ratios are constant over time holds for these covariates.
	
	\subsection{Schoenfeld Residuals for High Costs Pricing}
	
	Despite all covariates having p-values above 0.05, indicating no strong evidence against the proportional hazard’s assumption, High Costs Pricing (p = 0.06) tends to be very close to the threshold of 0.05 thus implying that, the Schoenfeld residual plot for this covariate is necessary to determine if there is any visible pattern over time. 
	
	Schoenfeld residuals are a diagnostic tool used in survival analysis to test the proportional hazards assumption of the Cox Proportional Hazards model. They are the differences between observed event times and the expected event times, under the model, at each event time.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.4\linewidth]{Figure 4/4.3.png}
		\caption{Schoenfeld residuals of High Costs Pricing}
		\label{Figure 4.3}
	\end{figure}
	
	Based on the visual inspection of the Schoenfeld residuals plot for High Costs Pricing, there does not appear to be a strong violation of the proportional hazard’s assumption since the p-value for High Costs Pricing was not less than the threshold (0.05). The visual inspection further supports that there might not be a significant violation as there is no obvious trend or pattern in the residuals over time, which suggests that the proportional hazards assumption might hold for this covariate.
	
	
	\section{Accelerated Failure Time (AFT) }
	
	The Accelerated Failure Time (AFT) model is often used when the Cox Proportional Hazard (PH) model does not hold. Although the null hypothesis of Cox PH was accepted, the study still uses the AFT in order to understand the direct effect of covariates on survival time and to make predictions about survival times.
	
	\begin{itemize}
		\item Weibull AFT Fitter: AIC = 815.516
		\item 	Lognormal AFT Fitter: AIC = 822.647
		\item 	Loglogistic AFT Fitter: AIC = 820.250
		
		
	\end{itemize}
	
	Among these models, the Weibull AFT Fitter has the lowest AIC value with 815.516, thereby providing the best fit to the data compared to the Lognormal and Loglogistic models. This means that, based on the AIC criterion, the Weibull distribution is the most appropriate for modeling your survival data in this context.
	
	\subsection{Weibull Model}
	% Table here
	
	\begin{table}[H]
		\centering
		\begin{tabular}{lccc}
			\toprule
			\textbf{Covariates} & \textbf{Coefficient} & \textbf{EXP(Coefficient)} & \textbf{P} \\
			\midrule
			College & 0.017 & 1.017 & 0.440 \\
			Data Exhaustion & -0.176 & 0.839 & 0.102 \\
			Gender & 0.218 & 1.244 & 0.006 \\
			High Costs Pricing & -0.06 & 0.941 & 0.423 \\
			Insufficient Data Allowance & -0.050 & 0.951 & 0.521 \\
			Mobile Data Internet & -0.118 & 0.889 & 0.335 \\
			Monthly Data Usage & 0.026 & 1.026 & 0.374 \\
			Multiple Networks & -0.104 & 0.901 & 0.546 \\
			Network Strength & -0.093 & 0.911 & 0.008 \\
			Other Networks Better Services & -0.052 & 0.950 & 0.633 \\
			Poor Network Quality Coverage & 0.071 & 1.073 & 0.378 \\
			Residence & 0.032 & 1.032 & 0.698 \\
			SMS Text Messaging & 0.039 & 1.040 & 0.600 \\
			Unsatisfactory Customer Service & 0.063 & 1.065 & 0.406 \\
			Usage Freq & 0.002 & 1.002 & 0.936 \\
			Voice Calls & -0.080 & 0.923 & 0.421 \\
			Intercept (lambda) & 2.112 & 8.266 & 0.00005 \\
			Intercept (rho) & 0.906 & 2.471 & 0.00005 \\
			\bottomrule
		\end{tabular}
		\caption{Coefficients and their Exponentiated Values with P-values}
	\end{table}
	
	Just like the Cox PH analysis, the coefficient and exp(coefficient) columns in Table 4.4 provide information about the relationship between the covariates to churn. A positive coefficient or exp(coefficient) \(> \) 1 (such as Residence and Poor Network Quality Coverage) indicates that an increase in the covariate is associated with an increase in the time to the event. These increase the time to churn. A positive coefficient in a Weibull AFT model means the covariate increases the time to the event, indicating a protective effect against the event occurring sooner.
	
	A negative coefficient or exp(coefficient)  \(< \) 1 (such as Data Exhaustion and Network Strength) suggests a decrease in the time to the event. These decrease the time to churn. A higher value of these covariates is associated with a higher likelihood of churn.
	The p-value column helps assess the statistical significance of each covariate. A low p-value (typically  \(< \) 0.05) indicates that the covariate is likely to have a meaningful impact on churn. This can be seen in Network Strength and Gender.
	
	The intercept (lambda) with a coefficient of 2.112 and p-value of 0.00005, indicates a highly significant baseline increase in time to event and the intercept (rho) coefficient is 0.906 and a p-value of 0.00005 therefore indicating a highly significant baseline multiplicative effect on time to event.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{Figure 4/4.4.png}
		\caption{Weibull Coefficients}
	\end{figure}
	
	The boxes (squares) in the plot represent the estimated coefficients for each factor in the Weibull AFT mode in Figure 4.4. These coefficients indicate the effect size of each covariate on the accelerated failure rate (churn). The positive values suggest that the covariate speeds up the churn rate, while negative values suggest it slows down the event (decreases the churn rate). The horizontal lines extending from the boxes are the 95\% confidence intervals, showing the uncertainty around these estimates. If the confidence interval crosses zero, the covariate is not statistically significant.
	
	\section{Model Comparison}
	
	In this section, the models used are compared based on the AIC and the concordance values. The higher the concordance, the better the model predictive value and the smaller the AIC, the better the model fit.
	
	%Table here
	\begin{table}[H]
		\centering
		\begin{tabular}{lcc}
			\toprule
			\textbf{Model} & \textbf{Concordance} & \textbf{AIC} \\
			\midrule
			Weibull & 0.624 & 815.516 \\
			Cox PH & 0.62 & 1479.47 \\
			\bottomrule
		\end{tabular}
		\caption{Model Concordance and AIC values}
	\end{table}
	
	Based on the comparison of the C-Index values and AIC in Table 4.5, it is known that the Weibull model shows a substantially lower AIC, indicating a better overall fit compared to the Cox PH model for churn modeling of telecommunication. The concordance index of the Weibull is slightly higher than that of the Cox PH thus implying that, the Weibull has a better predictive ability.
	
	\newpage
	\chapter{Conclusion}
	
	
	
	
	
	\begin{thebibliography}{9}
		\bibitem{bandim2022} 
		Bandim, M. (2022). Growth of Ghana's Telecommunications Industry. \textit{Journal of African Telecommunications}, 45(2), 123-135.
		
		\bibitem{ghanaweb2023} 
		Ghana Web. (2023). Underwater Fiber Optic Cable Outages Impact Telecommunications in West Africa. Retrieved from Ghana Web.
		
		\bibitem{kapur2018} 
		Kapur, R. (2018). Factors Driving Customer Churn in Telecom Industry. \textit{International Journal of Telecom Studies}, 22(4), 321-334.
		
		\bibitem{koranchirath2024} 
		Koranchirath, A. (2024). Customer Retention Strategies in Competitive Markets. \textit{Telecom Review}, 30(1), 56-72.
		
		\bibitem{apnews2023} 
		AP News. (2023). Underwater Cable Disruptions Affect West Africa's Internet Services. Retrieved from AP News.
		
		\bibitem{Alqatani2020} Alqatani, A. \& Altarifi, A. (2020). Title of the paper. Journal Name, Volume(Issue), Pages.
		\bibitem{BoxSteffensmeier2020} Box-Steffensmeier, J. \& Jone, C. (2020). Title of the paper. Journal Name, Volume(Issue), Pages.
		\bibitem{Lai2021} Lai, T., et al. (2021). Title of the paper. Journal Name, Volume(Issue), Pages.
		\bibitem{SmithBrown2020} Smith, R. \& Brown, J. (2020). Title of the paper. Journal Name, Volume(Issue), Pages.
		\bibitem{Jerenz2008} Jerenz, A. (2008). Title of the paper. Journal Name, Volume(Issue), Pages.
		\bibitem{Kaplan1958} Kaplan, E. \& Meier, P. (1958). Title of the paper. Journal Name, Volume(Issue), Pages.
		\bibitem{Cox1972} Cox, D. (1972). Title of the paper. Journal Name, Volume(Issue), Pages.
		\bibitem{Lee2014} Lee, M. (2014). Business Bankruptcy Prediction Based on Survival Analysis Approach. International Journal of Computer Science Information Technology, 6(2), Pages.
		\bibitem{Pereira2014} Pereira, J. (2014). Survival Analysis Employed in Predicting Corporate Failure: A Forecasting Model Proposal. International Business Research, 7(6), Pages.
		\bibitem{Kumar2015} Kumar, K. \& Gepp, A. (2015). Predicting Financial Distress: A Comparison of Survival Analysis and Decision Tree Techniques. Procedia Computer Science, 54(2), 396-404.
		\bibitem{Iwasaki2014} Iwasaki, I. (2014). Global Financial Crisis, Corporate Governance, and Firm Survival: The Russian Experience. Journal of Comparative Economics, 42(1), 178-211.
		\bibitem{Leung2010} Leung, M. K., Rigby, D., \& Young, T. (2010). Entry of Foreign Banks in the People's Republic of China: A Survival Analysis. Journal of Applied Economics, 10, 21-31.
		\bibitem{Evrensel2008} Evrensel, A. Y. (2008). Banking Crisis and Financial Structure: A Survival-Time Analysis. International Review of Economics and Finance, 17(4), 589-602.
		\bibitem{Tsujitani2012} Tsujitani, M. \& Baesens, B. (2012). Survival Analysis for Personal Loan Data Using Generalized Additive Models. Behaviormetrika, 39(1), 1109, 9-23.
		\bibitem{Baesens2005} Baesens, B., Gestel, T. V., Stepanova, M., Poel, D. V., \& Vanthienen, J. (2005). Neural Network Survival Analysis for Personal Loan Data. Journal of the Operational Research Society, 56(9), 1089-109
		
	\end{thebibliography}
	
\end{document}
